---
title: "Reporte: Replicación de resultados a Customer Churn Prediction"
author: "Gerardo Andrés Montero, César Salazar, Oscar Espinoza, Andy Peralta"
date: today
format:
  html: default
  pdf: default

---

# Introducción

En el entorno competitivo de la industria de las telecomunicaciones, la retención de clientes se ha convertido en un desafío estratégico de primer orden. La capacidad para predecir cuándo un cliente podría abandonar un servicio —lo que se conoce como *customer churn*— representa una ventaja significativa en términos de optimización de campañas de retención, reducción de pérdidas económicas y fortalecimiento del valor de marca.

En este contexto, el uso de modelos de predicción basados en técnicas de *Machine Learning* y *Deep Learning* ha ganado una gran relevancia en los últimos años debido a su capacidad para modelar grandes volúmenes de datos con una alta precisión.

La presente bitácora se basa en la profundización de un estudio anterior centrado en la predicción de abandono de clientes utilizando aprendizaje profundo. El objetivo es investigar más a fondo la metodología empleada, identificar las técnicas más efectivas implementadas, y comprender cómo estas pueden ser replicadas o adaptadas para aplicaciones prácticas, como el desarrollo de un sistema propio basado en datos de clientes de telecomunicaciones.

El estudio de referencia es el artículo *“Customer Churn Prediction in Telecommunication Industry Using Deep Learning”* (Fujo, Subramanian y Khder, 2022), el cual propone un enfoque robusto y replicable que servirá de base para la implementación futura del código y análisis del modelo.

# Exploración

El artículo plantea la implementación de una red neuronal profunda con retropropagación (*Deep-BP-ANN*) como alternativa más efectiva frente a técnicas tradicionales como regresión logística, KNN, Naïve Bayes o XGBoost.

El modelo fue entrenado y validado utilizando dos bases de datos ampliamente reconocidas en el área: **IBM Telco** y **Cell2Cell**, las cuales presentan escenarios reales de clientes y problemas típicos de desbalance de clases (entre clientes que permanecen y los que abandonan).

# Metodología

-   **Preprocesamiento de datos:** Se aplicó imputación de valores faltantes, codificación de variables categóricas (label y one-hot encoding), y normalización de variables numéricas con varianza alta mediante `MinMaxScaler`.

-   **Selección de características:** Se usaron dos enfoques complementarios —Lasso Regression y Variance Thresholding— para eliminar atributos irrelevantes y mejorar la eficiencia del modelo.

-   **Tratamiento del desbalance:** Dada la desproporción entre clases (aproximadamente 26–29% de churn en ambos conjuntos), se utilizó *Random Oversampling*.

-   **Arquitectura del modelo:** El modelo Deep-BP-ANN fue optimizado con 250 neuronas por capa, dos capas ocultas, función de activación *ReLU* en capas internas y *sigmoid* en la capa de salida. También se emplearon:

    -   *Early Stopping*
    -   *Activity Regularization*

-   **Evaluación del modelo:** Se utilizaron validaciones *Holdout* y *10-fold Cross Validation*, y métricas como:

    -   Accuracy
    -   Recall
    -   Precision
    -   F1-Score
    -   AUC

# Resultados

Los resultados muestran que el modelo propuesto supera tanto a algoritmos tradicionales como a otros modelos de deep learning:

-   **88.12% de exactitud** en IBM Telco (holdout)
-   **79.38% de exactitud** en Cell2Cell

Esto representa mejoras respecto a modelos ANN previos (80–85%).

> La calidad y relevancia de las variables predictoras incide más que el tamaño del dataset en el rendimiento del modelo.

## Gráficos

![](imagenes/grafica_01.png)

*Fuente: Fujo, Subramanian y Khder (2022)*

![](imagenes/grafica_02.png)

*Fuente: Fujo, Subramanian y Khder (2022)*

## Hallazgos Relevantes

-   Las variables más influyentes en IBM Telco fueron el **cargo total** y la **antigüedad del cliente**.
-   Se confirma que la calidad de las variables es más crítica que la cantidad de datos.
-   El modelo Deep-BP-ANN superó a enfoques con CNN, ANN y *transfer learning*.

### Modelo XGB

El modelo XGB, implementado en Python con la librería xgboost, presentó el siguiente desempeño:

Métricas de evaluación:
Clase 0 (No Churn):

Precisión: 0.84 — acierta el 84 % al predecir "No Churn".

Recall: 0.77 — detecta el 77 % de los casos reales de "No Churn".

F1-score: 0.80 — buen balance entre precisión y recall.

Clase 1 (Churn):

Precisión: 0.78 — acierta el 78 % al predecir "Churn".

Recall: 0.85 — identifica el 85 % de los casos reales de "Churn".

F1-score: 0.82 — refleja un desempeño sólido y balanceado.

La precisión global (accuracy) alcanzó un 81 %, lo que muestra un rendimiento general aceptable. Este resultado destaca especialmente en la clase "Churn", donde el recall es alto (0.85), lo que indica que el modelo tiene buena capacidad para identificar clientes que efectivamente abandonan el servicio.

Para mejorar, se podrían usar técnicas como SMOTE, optimización de hiperparámetros o análisis de importancia de características. Comparado con el Deep-BP-ANN del papper(88.12% de precisión), XGB es ligeramente inferior, pero más eficiente computacionalmente.

| Evaluacion modelo XGBOOST |           |       |          |
|:-------------------------:|:---------:|:-----:|:--------:|
|                           | Precicion | recal | F1-score |
|             0             |    0.84   |  0.77 |   0.80   |
|             1             |    0.78   |  0.85 |   0.82   |
|           Final           |    0.81   |       |          |


## Modelo NB (Naive Bayes)

La matriz de confusión nos permite analizar en detalle el desempeño:

True Negatives : 369 — Predijo correctamente que el cliente no se iba (clase 0).

False Positives : 149 — Predijo que el cliente se iba, pero en realidad no se fue.

False Negatives : 100 — Predijo que el cliente no se iba, pero sí se fue.

True Positives : 417 — Predijo correctamente que el cliente se iba (clase 1).

### Métricas de evaluación

Clase 0 (No churn):
Precisión: 0.79  El modelo se equivoca poco cuando predice que el cliente no se va.

Recall: 0.71  Detecta el 71% de los que realmente no se van.

F1-score: 0.75  Equilibrio entre precisión y recall.

Clase 1 (Churn):
Precisión: 0.74  Cuando predice que se va, solo el 74% es cierto.

Recall: 0.81  Captura el 81% de los clientes que efectivamente se van.

F1-score: 0.77  Moderadamente útil para detectar churn.

| Evaluacion modelo NB |           |       |          |
|:--------------------:|:---------:|:-----:|:--------:|
|                      | Precicion | recal | F1-score |
|           0          |    0.79   |  0.71 |   0.75   |
|           1          |    0.74   |  0.81 |   0.77   |
|         Final        |    0.76   |       |          |



## Modelo BPANN
Época final (epoch): Variable, entre 60 y 160.
El entrenamiento se detuvo entre los 60 y 160 cicloscompletos de entrenamiento a través de todos los datos de entrada, deteniendose cuando el error dejara de disminuir.

Error final promedio: 0.36%
Este valor representa el error acumulado al final del entrenamiento. 

### Métricas de evaluación:
Clase 0 (No Churn):

Precisión: 0.74 — acierta el 74 % al predecir "No Churn".

Recall: 0.83 — detecta el 83 % de los clientes que realmente no abandonan.

F1-score: 0.78 — buen equilibrio entre precisión y recall.

Clase 1 (Churn):

Precisión: 0.81 — acierta el 81 % al predecir "Churn".

Recall: 0.70 — identifica el 70 % de los clientes que efectivamente abandonan.

F1-score: 0.75 — refleja un desempeño aceptable, aunque con oportunidad de mejorar el recall.

La precisión global (accuracy) fue de 77 %, mostrando un rendimiento moderado y balanceado.

Notamos que el uso del modelo BPANN es el mas alto, en este caso no tan cercano al estudio debido al poder computacional que es un factor limitande debido a el consumo energetico, de tiempo y dinero. Aun asi, el modelo predice satisfactoriamente.

Aqui podemos ver los resultados:

| Evaluacion modelo BPANN |           |       |          |
|:-----------------------:|:---------:|:-----:|:--------:|
|                         | Precicion | recal | F1-score |
|            0            |    0.74   |  0.83 |   0.78   |
|            1            |    0.81   |  0.70 |   0.75   |
|          Final          |    0.77   |       |          |

# Análisis FODA

## Fortalezas

-   **Metodología sólida y bien documentada**: El proyecto se basa en un estudio académico robusto (Fujo et al., 2022) y utiliza el dataset reconocido IBM Telco, lo que garantiza una base confiable y replicable.

-   **Uso de técnicas avanzadas de Machine Learning**: La implementación del modelo Deep-BP-ANN, optimizado con *Early Stopping* y *Activity Regularization*, logra una alta precisión (88.12% en IBM Telco), superando a modelos tradicionales.

-   **Análisis comparativo exhaustivo**: La evaluación de múltiples modelos (XGB: 81%, NB: 76%, BPANN: 77%) con métricas claras (Accuracy, Precision, Recall, F1-Score, AUC) permite una comparación objetiva y fundamentada.

-   **Tratamiento efectivo del desbalance de clases**: El uso de *Random Oversampling* mejora la predicción de la clase minoritaria (*churn*), crucial para aplicaciones prácticas.

-   **Selección de características optimizada**: La combinación de *Lasso Regression* y *Variance Thresholding* elimina variables irrelevantes, aumentando la eficiencia y precisión del modelo.

-   **Replicabilidad y transparencia**: La disponibilidad del código en un repositorio GitHub y la documentación detallada facilita la adaptación del proyecto a otros contextos.

-   **Identificación de variables clave**: La determinación de variables predictoras críticas, como el *cargo total* y la *antigüedad del cliente*, proporciona *insights* accionables para estrategias de retención.

## Oportunidades

-   **Aplicación práctica en telecomunicaciones**: Los modelos predictivos pueden implementarse en empresas reales para optimizar campañas de retención, reduciendo el *churn* y mejorando la rentabilidad.

-   **Escalabilidad a otros sectores**: La metodología es adaptable a industrias con problemas similares, como banca, seguros o comercio electrónico, ampliando su impacto.

-   **Adopción de técnicas avanzadas**: Incorporar métodos como SMOTE, optimización de hiperparámetros o *ensemble learning* puede mejorar aún más el rendimiento de los modelos.

-   **Acceso a datasets más diversos**: Utilizar datasets más grandes o actualizados, como datos en tiempo real de empresas, puede mejorar la generalización de los modelos.

-   **Infraestructura computacional avanzada**: Con acceso a mayor poder computacional (por ejemplo, GPUs o servicios en la nube), se podrían explorar arquitecturas más complejas o entrenamientos prolongados.

-   **Colaboración interdisciplinaria**: Asociarse con expertos en ciencia de datos, marketing o dominio del negocio puede enriquecer el análisis y la aplicación práctica de los resultados.

-   **Integración con tecnologías emergentes**: Incorporar herramientas como *AutoML* o modelos basados en *transformers* podría modernizar el enfoque y mejorar la competitividad.

## Debilidades

-   **Limitaciones computacionales**: El modelo Deep-BP-ANN requiere alto consumo de recursos (energía, tiempo, dinero), lo que dificulta su implementación en entornos con infraestructura limitada.

-   **Desempeño inferior de modelos alternativos**: Los modelos XGB (81%) y NB (76%) son menos precisos que el Deep-BP-ANN (88.12%), lo que limita las opciones en escenarios con restricciones computacionales.

-   **Dependencia de la calidad de los datos**: La efectividad del modelo depende de datos limpios y relevantes, y datasets ruidosos o incompletos podrían reducir su precisión.

-   **Falta de optimización exhaustiva de hiperparámetros**: La ausencia de un análisis detallado de hiperparámetros puede estar limitando el rendimiento óptimo de los modelos.

-   **Recall moderado en la clase Churn para BPANN**: Con un recall de 0.70 para la clase *Churn*, el modelo BPANN podría omitir casos de abandono, lo que es crítico para aplicaciones prácticas.

-   **Falta de validación en datasets externos**: Los modelos se probaron en IBM Telco y Cell2Cell, pero no se validaron en otros datasets, lo que podría limitar su generalización.

-   **Documentación limitada sobre implementación práctica**: Aunque el código está disponible, no se detalla cómo implementar los modelos en un entorno real de telecomunicaciones.

## Amenazas

-   **Competencia tecnológica**: Otras empresas pueden estar desarrollando modelos más avanzados (por ejemplo, basados en *transformers* o *ensemble learning*), superando los resultados del proyecto.

-   **Obsolescencia tecnológica**: Las técnicas de *Deep Learning* evolucionan rápidamente, y el enfoque Deep-BP-ANN podría quedar desactualizado frente a nuevos paradigmas.

-   **Restricciones de datos**: Regulaciones de privacidad (como GDPR) pueden limitar el acceso a datos reales de clientes, afectando la escalabilidad del modelo.

-   **Costo de implementación**: La adopción de modelos como Deep-BP-ANN en entornos reales requiere inversión en infraestructura y mantenimiento, lo que puede ser prohibitivo.

-   **Riesgo de sobreajuste**: A pesar de técnicas como *Early Stopping*, los modelos podrían no generalizar bien en datasets con distribuciones diferentes a las utilizadas.

-   **Expectativas del mercado**: Las empresas pueden esperar resultados más rápidos o modelos más simples, lo que podría dificultar la adopción de enfoques complejos como Deep-BP-ANN.

# Conclusiones y recomendaciones

> La calidad y relevancia de las variables predictoras incide más que el tamaño del dataset en el rendimiento del modelo.

# Referencias

Fujo, S. W., Subramanian, S., & Khder, M. A. (2022). *Customer churn prediction in telecommunication industry using deep learning*. Information Sciences Letters, 11(1), 185–198. <https://digitalcommons.aaru.edu.jo/isl/vol11/iss1/24>

DataCamp. (s.f.). Naive Bayes Classification with Scikit-Learn. Recuperado el 7 de junio de 2025 de <https://www.datacamp.com/tutorial/naive-bayes-scikit-learn>

Pedregosa, F., et al. (s.f.). Naive Bayes — scikit-learn 1.4.2 documentation. Recuperado el 7 de junio de 2025 de <https://scikit-learn.org/stable/modules/naive_bayes.html>

Simplilearn. (s.f.). What is Epoch in Machine Learning? Simplilearn. <https://www.simplilearn.com/tutorials/machine-learning-tutorial/what-is-epoch-in-machine-learning>

Gupta, P. (2021). Comprehensive guide to artificial neural networks with Keras \[Notebook\]. Kaggle. <https://www.kaggle.com/code/prashant111/comprehensive-guide-to-ann-with-keras/notebook>

Scikit-learn. (s.f.). Developing scikit-learn estimators. Scikit-learn. <https://scikit-learn.org/stable/developers/develop.html>

XGBoost. (s.f.). Python package introduction. XGBoost. <https://xgboost.readthedocs.io/en/stable/python/python_intro.html>

Jain, A. (2016, 17 de marzo). Complete guide to parameter tuning in XGBoost with codes in Python. Analytics Vidhya. <https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/>

XGBoost. (s.f.). Introduction to boosted trees. XGBoost. <https://xgboost.readthedocs.io/en/stable/tutorials/model.html>

Chen, T., & Guestrin, C. (2016). XGBoost: A scalable tree boosting system. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 785–794. <https://doi.org/10.1145/2939672.2939785>

Techtonique. (2025, 1 de enero). Explaining XGBoost predictions with the Teller. Techtonique. <https://www.techtonique.net/post/explaining-xgboost-predictions-teller/>

Brownlee, J. (s.f.). Gradient boosting with scikit-learn, XGBoost, LightGBM, and CatBoost. Machine Learning Mastery. <https://machinelearningmastery.com/gradient-boosting-with-scikit-learn-xgboost-lightgbm-and-catboost/>

Enlace a repositorio GitHub: <https://github.com/CisarUli/Proyecto_CA0305_Grupo_02>
