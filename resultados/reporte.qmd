---
title: "Reporte: Replicación de resultados a Customer Churn Prediction"
author: "Gerardo Andrés Montero, César Salazar, Oscar Espinoza, Andy Peralta"
date: today
format:
  html: default
  pdf: default

---

# Introducción

En el entorno competitivo de la industria de las telecomunicaciones, la retención de clientes se ha convertido en un desafío estratégico de primer orden. La capacidad para predecir cuándo un cliente podría abandonar un servicio —lo que se conoce como *customer churn*— representa una ventaja significativa en términos de optimización de campañas de retención, reducción de pérdidas económicas y fortalecimiento del valor de marca.

En este contexto, el uso de modelos de predicción basados en técnicas de *Machine Learning* y *Deep Learning* ha ganado una gran relevancia en los últimos años debido a su capacidad para modelar grandes volúmenes de datos con una alta precisión.

La presente bitácora se basa en la profundización de un estudio anterior centrado en la predicción de abandono de clientes utilizando aprendizaje profundo. El objetivo es investigar más a fondo la metodología empleada, identificar las técnicas más efectivas implementadas, y comprender cómo estas pueden ser replicadas o adaptadas para aplicaciones prácticas, como el desarrollo de un sistema propio basado en datos de clientes de telecomunicaciones.

El estudio de referencia es el artículo *“Customer Churn Prediction in Telecommunication Industry Using Deep Learning”* (Fujo, Subramanian y Khder, 2022), el cual propone un enfoque robusto y replicable que servirá de base para la implementación futura del código y análisis del modelo.

# Exploración

El artículo plantea la implementación de una red neuronal profunda con retropropagación (*Deep-BP-ANN*) como alternativa más efectiva frente a técnicas tradicionales como regresión logística, KNN, Naïve Bayes o XGBoost.

El modelo fue entrenado y validado utilizando dos bases de datos ampliamente reconocidas en el área: **IBM Telco** y **Cell2Cell**, las cuales presentan escenarios reales de clientes y problemas típicos de desbalance de clases (entre clientes que permanecen y los que abandonan).

# Metodología

-   **Preprocesamiento de datos:** Se aplicó imputación de valores faltantes, codificación de variables categóricas (label y one-hot encoding), y normalización de variables numéricas con varianza alta mediante `MinMaxScaler`.

-   **Selección de características:** Se usaron dos enfoques complementarios —Lasso Regression y Variance Thresholding— para eliminar atributos irrelevantes y mejorar la eficiencia del modelo.

-   **Tratamiento del desbalance:** Dada la desproporción entre clases (aproximadamente 26–29% de churn en ambos conjuntos), se utilizó *Random Oversampling*.

-   **Arquitectura del modelo:** El modelo Deep-BP-ANN fue optimizado con 250 neuronas por capa, dos capas ocultas, función de activación *ReLU* en capas internas y *sigmoid* en la capa de salida. También se emplearon:

    -   *Early Stopping*
    -   *Activity Regularization*

-   **Evaluación del modelo:** Se utilizaron validaciones *Holdout* y *10-fold Cross Validation*, y métricas como:

    -   Accuracy
    -   Recall
    -   Precision
    -   F1-Score
    -   AUC

# Resultados

Los resultados muestran que el modelo propuesto supera tanto a algoritmos tradicionales como a otros modelos de deep learning:

-   **88.12% de exactitud** en IBM Telco (holdout)
-   **79.38% de exactitud** en Cell2Cell

Esto representa mejoras respecto a modelos ANN previos (80–85%).

> La calidad y relevancia de las variables predictoras incide más que el tamaño del dataset en el rendimiento del modelo.

## Gráficos

![](imagenes/grafica_01.png)

*Fuente: Fujo, Subramanian y Khder (2022)*

![](imagenes/grafica_02.png)

*Fuente: Fujo, Subramanian y Khder (2022)*

## Hallazgos Relevantes

-   Las variables más influyentes en IBM Telco fueron el **cargo total** y la **antigüedad del cliente**.
-   Se confirma que la calidad de las variables es más crítica que la cantidad de datos.
-   El modelo Deep-BP-ANN superó a enfoques con CNN, ANN y *transfer learning*.

### Modelo XGB

El modelo XGB, implementado en Python con la librería xgboost, presentó el siguiente desempeño:

Métricas de evaluación:
Clase 0 (No Churn):

Precisión: 0.84 — acierta el 84 % al predecir "No Churn".

Recall: 0.77 — detecta el 77 % de los casos reales de "No Churn".

F1-score: 0.80 — buen balance entre precisión y recall.

Clase 1 (Churn):

Precisión: 0.78 — acierta el 78 % al predecir "Churn".

Recall: 0.85 — identifica el 85 % de los casos reales de "Churn".

F1-score: 0.82 — refleja un desempeño sólido y balanceado.

La precisión global (accuracy) alcanzó un 81 %, lo que muestra un rendimiento general aceptable. Este resultado destaca especialmente en la clase "Churn", donde el recall es alto (0.85), lo que indica que el modelo tiene buena capacidad para identificar clientes que efectivamente abandonan el servicio.

Para mejorar, se podrían usar técnicas como SMOTE, optimización de hiperparámetros o análisis de importancia de características. Comparado con el Deep-BP-ANN del papper(88.12% de precisión), XGB es ligeramente inferior, pero más eficiente computacionalmente.

| Evaluacion modelo XGBOOST |           |       |          |
|:-------------------------:|:---------:|:-----:|:--------:|
|                           | Precicion | recal | F1-score |
|             0             |    0.84   |  0.77 |   0.80   |
|             1             |    0.78   |  0.85 |   0.82   |
|           Final           |    0.81   |       |          |


## Modelo NB (Naive Bayes)

La matriz de confusión nos permite analizar en detalle el desempeño:

True Negatives : 369 — Predijo correctamente que el cliente no se iba (clase 0).

False Positives : 149 — Predijo que el cliente se iba, pero en realidad no se fue.

False Negatives : 100 — Predijo que el cliente no se iba, pero sí se fue.

True Positives : 417 — Predijo correctamente que el cliente se iba (clase 1).

### Métricas de evaluación

Clase 0 (No churn):
Precisión: 0.79  El modelo se equivoca poco cuando predice que el cliente no se va.

Recall: 0.71  Detecta el 71% de los que realmente no se van.

F1-score: 0.75  Equilibrio entre precisión y recall.

Clase 1 (Churn):
Precisión: 0.74  Cuando predice que se va, solo el 74% es cierto.

Recall: 0.81  Captura el 81% de los clientes que efectivamente se van.

F1-score: 0.77  Moderadamente útil para detectar churn.

| Evaluacion modelo NB |           |       |          |
|:--------------------:|:---------:|:-----:|:--------:|
|                      | Precicion | recal | F1-score |
|           0          |    0.79   |  0.71 |   0.75   |
|           1          |    0.74   |  0.81 |   0.77   |
|         Final        |    0.76   |       |          |



## Modelo BPANN
Época final (epoch): Variable, entre 60 y 160.
El entrenamiento se detuvo entre los 60 y 160 cicloscompletos de entrenamiento a través de todos los datos de entrada, deteniendose cuando el error dejara de disminuir.

Error final promedio: 0.36%
Este valor representa el error acumulado al final del entrenamiento. 

### Métricas de evaluación:
Clase 0 (No Churn):

Precisión: 0.74 — acierta el 74 % al predecir "No Churn".

Recall: 0.83 — detecta el 83 % de los clientes que realmente no abandonan.

F1-score: 0.78 — buen equilibrio entre precisión y recall.

Clase 1 (Churn):

Precisión: 0.81 — acierta el 81 % al predecir "Churn".

Recall: 0.70 — identifica el 70 % de los clientes que efectivamente abandonan.

F1-score: 0.75 — refleja un desempeño aceptable, aunque con oportunidad de mejorar el recall.

La precisión global (accuracy) fue de 77 %, mostrando un rendimiento moderado y balanceado.

Notamos que el uso del modelo BPANN es el mas alto, en este caso no tan cercano al estudio debido al poder computacional que es un factor limitande debido a el consumo energetico, de tiempo y dinero. Aun asi, el modelo predice satisfactoriamente.

Aqui podemos ver los resultados:

| Evaluacion modelo BPANN |           |       |          |
|:-----------------------:|:---------:|:-----:|:--------:|
|                         | Precicion | recal | F1-score |
|            0            |    0.74   |  0.83 |   0.78   |
|            1            |    0.81   |  0.70 |   0.75   |
|          Final          |    0.77   |       |          |

# Analisis FODA

# Referencias

Fujo, S. W., Subramanian, S., & Khder, M. A. (2022). *Customer churn prediction in telecommunication industry using deep learning*. Information Sciences Letters, 11(1), 185–198. <https://digitalcommons.aaru.edu.jo/isl/vol11/iss1/24>

DataCamp. (s.f.). Naive Bayes Classification with Scikit-Learn. Recuperado el 7 de junio de 2025 de https://www.datacamp.com/tutorial/naive-bayes-scikit-learn

Pedregosa, F., et al. (s.f.). Naive Bayes — scikit-learn 1.4.2 documentation. Recuperado el 7 de junio de 2025 de https://scikit-learn.org/stable/modules/naive_bayes.html


Simplilearn. (s.f.). What is Epoch in Machine Learning? Simplilearn. https://www.simplilearn.com/tutorials/machine-learning-tutorial/what-is-epoch-in-machine-learning

Gupta, P. (2021). Comprehensive guide to artificial neural networks with Keras [Notebook]. Kaggle. https://www.kaggle.com/code/prashant111/comprehensive-guide-to-ann-with-keras/notebook

Scikit-learn. (s.f.). Developing scikit-learn estimators. Scikit-learn. https://scikit-learn.org/stable/developers/develop.html

XGBoost. (s.f.). Python package introduction. XGBoost. https://xgboost.readthedocs.io/en/stable/python/python_intro.html

Jain, A. (2016, 17 de marzo). Complete guide to parameter tuning in XGBoost with codes in Python. Analytics Vidhya. https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/

XGBoost. (s.f.). Introduction to boosted trees. XGBoost. https://xgboost.readthedocs.io/en/stable/tutorials/model.html

Chen, T., & Guestrin, C. (2016). XGBoost: A scalable tree boosting system. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 785–794. https://doi.org/10.1145/2939672.2939785

Techtonique. (2025, 1 de enero). Explaining XGBoost predictions with the Teller. Techtonique. https://www.techtonique.net/post/explaining-xgboost-predictions-teller/

Brownlee, J. (s.f.). Gradient boosting with scikit-learn, XGBoost, LightGBM, and CatBoost. Machine Learning Mastery. https://machinelearningmastery.com/gradient-boosting-with-scikit-learn-xgboost-lightgbm-and-catboost/



Enlace a repositorio GitHub: https://github.com/CisarUli/Proyecto_CA0305_Grupo_02


